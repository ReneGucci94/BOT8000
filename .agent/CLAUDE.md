# Trading Bot v2 - Sistema de Trading Automatizado

## Objetivo
Construir un bot de trading robusto usando la estrategia TJR Price Action con arquitectura testeable y verificable.

## Reglas del Proyecto

### 1. Skills Obligatorias
ANTES de cualquier implementaciÃ³n, debo usar las skills en `.agent/skills/`:
- `brainstorming` â†’ Antes de crear features
- `writing-plans` â†’ Antes de implementar tareas multi-paso
- `executing-plans` â†’ Para ejecutar planes paso a paso
- `test-driven-development` â†’ SIEMPRE escribir test antes de cÃ³digo
- `verification-before-completion` â†’ Correr tests antes de decir "listo"

### 2. Arquitectura en Lenguaje Formal
TODO el cÃ³digo debe usar:
- Type hints estrictos (Python typing)
- Contratos formales (docstrings con INPUT/OUTPUT/ALGORITHM)
- Tests automÃ¡ticos (pytest)
- Clases inmutables donde sea posible (dataclasses con frozen=True)

### 3. Estrategia TJR Price Action
El bot implementa:
- Market Structure (HH/HL vs LH/LL)
- Break of Structure (BOS)
- Order Blocks (OB)
- Fair Value Gaps (FVG)
- Timeframes: 4H (bias), 1H (alignment), 5m/15m (entry)

### 4. Workflow Obligatorio
```
1. BRAINSTORM â†’ diseÃ±o
2. WRITE PLAN â†’ tareas de 2-5 min
3. EXECUTE con TDD â†’ test first, code second
4. VERIFY â†’ correr tests
5. DONE (solo si tests pasan)
```

## Estructura del Proyecto
- `src/` â†’ CÃ³digo de producciÃ³n
- `tests/` â†’ Tests automÃ¡ticos
- `.agent/skills/` â†’ Skills de desarrollo
# Superpowers: La Biblioteca Completa de Skills

Esta es la documentaciÃ³n completa del sistema Superpowers - el framework usado por desarrolladores profesionales para construir software sin errores.

**Por quÃ© esto vale oro:** Estas skills fueron creadas por Jesse Vincent (obra) despuÃ©s de aÃ±os de prueba y error con agentes de IA. Cada regla existe porque alguien la cagÃ³ sin ella.

---

# Ãndice

1. La Regla de Oro: using-superpowers
2. Skills de Proceso (cÃ³mo pensar)
3. Skills de EjecuciÃ³n (cÃ³mo hacer)
4. Skills de Calidad (cÃ³mo verificar)
5. Skills de Git (cÃ³mo organizar)
6. AplicaciÃ³n a Tu Bot de Trading v2

---

# 1. LA REGLA DE ORO

## using-superpowers

> **SI HAY 1% DE PROBABILIDAD DE QUE UNA SKILL APLIQUE, DEBES USARLA. NO ES OPCIONAL. NO ES NEGOCIABLE.**
> 

### El Flujo Obligatorio

```
Mensaje recibido
    â†“
Â¿Alguna skill podrÃ­a aplicar? (aunque sea 1%)
    â†“ SÃ
Invocar la skill
    â†“
Anunciar: "Estoy usando [skill] para [propÃ³sito]"
    â†“
Â¿Tiene checklist?
    â†“ SÃ
Crear TodoWrite con cada item
    â†“
Seguir la skill EXACTAMENTE
    â†“
Responder
```

### Pensamientos que Significan PARA - EstÃ¡s Racionalizando

| Pensamiento | Realidad |
| --- | --- |
| "Es una pregunta simple" | Las preguntas son tareas. Busca skills. |
| "Necesito mÃ¡s contexto primero" | Buscar skills viene ANTES de preguntas. |
| "DÃ©jame explorar el cÃ³digo primero" | Las skills te dicen CÃ“MO explorar. |
| "Puedo revisar git/archivos rÃ¡pido" | Los archivos no tienen contexto. Busca skills. |
| "Esto no necesita una skill formal" | Si existe una skill, Ãºsala. |
| "Me acuerdo de esta skill" | Las skills evolucionan. Lee la versiÃ³n actual. |
| "Es overkill" | Lo simple se vuelve complejo. Ãšsala. |
| "Voy a hacer esto primero" | Busca skills ANTES de hacer nada. |
| "Se siente productivo" | AcciÃ³n sin disciplina = tiempo perdido. |

### Prioridad de Skills

1. **Skills de proceso primero** (brainstorming, debugging) - determinan CÃ“MO abordar la tarea
2. **Skills de implementaciÃ³n despuÃ©s** (frontend-design, etc.) - guÃ­an la ejecuciÃ³n

---

# 2. SKILLS DE PROCESO

## brainstorming

> **OBLIGATORIO antes de cualquier trabajo creativo** - crear features, construir componentes, agregar funcionalidad.
> 

### El Proceso

**Entender la idea:**

- Revisar el estado actual del proyecto (archivos, docs, commits recientes)
- Hacer preguntas UNA A LA VEZ
- Preferir preguntas de opciÃ³n mÃºltiple cuando sea posible
- Solo una pregunta por mensaje
- Enfocarse en: propÃ³sito, restricciones, criterios de Ã©xito

**Explorar enfoques:**

- Proponer 2-3 enfoques diferentes con trade-offs
- Presentar opciones conversacionalmente con tu recomendaciÃ³n y razonamiento
- Liderar con la opciÃ³n recomendada y explicar por quÃ©

**Presentar el diseÃ±o:**

- Una vez que crees entender quÃ© se va a construir, presenta el diseÃ±o
- Dividir en secciones de 200-300 palabras
- Preguntar despuÃ©s de cada secciÃ³n si se ve bien
- Cubrir: arquitectura, componentes, flujo de datos, manejo de errores, testing

**DespuÃ©s del diseÃ±o:**

- Escribir el diseÃ±o validado a `docs/plans/YYYY-MM-DD-<tema>-[design.md](http://design.md)`
- Commit del documento de diseÃ±o a git

### Principios Clave

- **Una pregunta a la vez** - No abrumar con mÃºltiples preguntas
- **OpciÃ³n mÃºltiple preferido** - MÃ¡s fÃ¡cil de responder
- **YAGNI sin piedad** - Remover features innecesarias de todos los diseÃ±os
- **Explorar alternativas** - Siempre proponer 2-3 enfoques antes de decidir
- **ValidaciÃ³n incremental** - Presentar diseÃ±o en secciones, validar cada una

---

## writing-plans

> **Usar cuando tienes spec o requirements para una tarea multi-paso, ANTES de tocar cÃ³digo.**
> 

### Granularidad de Tareas

**Cada paso es UNA acciÃ³n (2-5 minutos):**

- "Escribir el test que falla" - paso
- "Correrlo para asegurar que falla" - paso
- "Implementar el cÃ³digo mÃ­nimo para que pase" - paso
- "Correr los tests y asegurar que pasan" - paso
- "Commit" - paso

### Header del Documento de Plan

**Cada plan DEBE empezar con este header:**

```markdown
# [Nombre de Feature] Plan de ImplementaciÃ³n

> **Para Claude:** SUB-SKILL REQUERIDA: Usar superpowers:executing-plans para implementar este plan tarea por tarea.

**Meta:** [Una oraciÃ³n describiendo quÃ© construye esto]

**Arquitectura:** [2-3 oraciones sobre el enfoque]

**Tech Stack:** [TecnologÃ­as/librerÃ­as clave]

---
```

### Estructura de Tarea

```markdown
### Tarea N: [Nombre del Componente]

**Archivos:**
- Crear: `ruta/exacta/al/[archivo.py](http://archivo.py)`
- Modificar: `ruta/exacta/al/[existente.py:123](http://existente.py:123)-145`
- Test: `tests/ruta/exacta/al/[test.py](http://test.py)`

**Paso 1: Escribir el test que falla**

[cÃ³digo del test]

**Paso 2: Correr test para verificar que falla**

Correr: `pytest tests/ruta/[test.py](http://test.py)::nombre_test -v`
Esperado: FAIL con "funciÃ³n no definida"

**Paso 3: Escribir implementaciÃ³n mÃ­nima**

[cÃ³digo mÃ­nimo]

**Paso 4: Correr test para verificar que pasa**

Correr: `pytest tests/ruta/[test.py](http://test.py)::nombre_test -v`
Esperado: PASS

**Paso 5: Commit**

```

git add tests/ruta/[test.py](http://test.py) src/ruta/[archivo.py](http://archivo.py)

git commit -m "feat: agregar feature especÃ­fica"

```

```

### Recuerda

- Rutas de archivo exactas siempre
- CÃ³digo completo en el plan (no "agregar validaciÃ³n")
- Comandos exactos con output esperado
- DRY, YAGNI, TDD, commits frecuentes

---

# 3. SKILLS DE EJECUCIÃ“N

## executing-plans

> **Usar cuando tienes un plan de implementaciÃ³n escrito para ejecutar en una sesiÃ³n separada con checkpoints de revisiÃ³n.**
> 

### El Proceso

**Paso 1: Cargar y Revisar Plan**

1. Leer archivo del plan
2. Revisar crÃ­ticamente - identificar preguntas o concerns
3. Si hay concerns: Plantearlos antes de empezar
4. Si no hay concerns: Crear TodoWrite y proceder

**Paso 2: Ejecutar Batch**

**Default: Primeras 3 tareas**

Para cada tarea:

1. Marcar como in_progress
2. Seguir cada paso exactamente
3. Correr verificaciones como se especifica
4. Marcar como completed

**Paso 3: Reportar**

Cuando el batch estÃ© completo:

- Mostrar quÃ© se implementÃ³
- Mostrar output de verificaciÃ³n
- Decir: "Listo para feedback."

**Paso 4: Continuar**

Basado en feedback:

- Aplicar cambios si es necesario
- Ejecutar siguiente batch
- Repetir hasta completar

### CuÃ¡ndo Parar y Pedir Ayuda

**PARA de ejecutar inmediatamente cuando:**

- Encuentres un blocker a medio batch
- El plan tiene gaps crÃ­ticos
- No entiendes una instrucciÃ³n
- La verificaciÃ³n falla repetidamente

**Pide clarificaciÃ³n en vez de adivinar.**

---

## dispatching-parallel-agents

> **Usar cuando enfrentas 2+ tareas independientes que pueden trabajarse sin estado compartido o dependencias secuenciales.**
> 

### CuÃ¡ndo Usar

**Usar cuando:**

- 3+ archivos de test fallando con diferentes causas raÃ­z
- MÃºltiples subsistemas rotos independientemente
- Cada problema puede entenderse sin contexto de los otros
- No hay estado compartido entre investigaciones

**NO usar cuando:**

- Las fallas estÃ¡n relacionadas (arreglar una podrÃ­a arreglar otras)
- Necesitas entender el estado completo del sistema
- Los agentes interferirÃ­an entre sÃ­

### El PatrÃ³n

**1. Identificar Dominios Independientes**

Agrupar fallas por quÃ© estÃ¡ roto:

- Archivo A tests: Flujo de aprobaciÃ³n
- Archivo B tests: Comportamiento de batch
- Archivo C tests: Funcionalidad de abort

**2. Crear Tareas de Agente Enfocadas**

Cada agente obtiene:

- **Scope especÃ­fico:** Un archivo de test o subsistema
- **Meta clara:** Hacer que estos tests pasen
- **Restricciones:** No cambiar otro cÃ³digo
- **Output esperado:** Resumen de quÃ© encontraste y arreglaste

**3. Dispatch en Paralelo**

```
Task("Arreglar agent-tool-abort.test.ts")
Task("Arreglar batch-completion-behavior.test.ts")
Task("Arreglar tool-approval-race-conditions.test.ts")
// Los tres corren concurrentemente
```

**4. Revisar e Integrar**

Cuando los agentes regresen:

- Leer cada resumen
- Verificar que los fixes no conflictÃºan
- Correr suite completa de tests
- Integrar todos los cambios

---

# 4. SKILLS DE CALIDAD

## test-driven-development (TDD)

> **Usar cuando implementas cualquier feature o bugfix, ANTES de escribir cÃ³digo de implementaciÃ³n.**
> 

### LA LEY DE HIERRO

```
NINGÃšN CÃ“DIGO DE PRODUCCIÃ“N SIN UN TEST QUE FALLE PRIMERO
```

**Â¿Escribiste cÃ³digo antes del test? BÃ³rralo. Empieza de nuevo.**

**Sin excepciones:**

- No lo guardes como "referencia"
- No lo "adaptes" mientras escribes tests
- No lo mires
- Borrar significa borrar

Implementa fresco desde los tests. Punto.

### Red-Green-Refactor

```
RED: Escribir test que falla
    â†“
Verificar que falla correctamente
    â†“
GREEN: CÃ³digo mÃ­nimo para pasar
    â†“
Verificar que pasa (todo verde)
    â†“
REFACTOR: Limpiar
    â†“
Verificar que sigue verde
    â†“
Siguiente test
```

### RED - Escribir Test que Falla

Escribir UN test mÃ­nimo mostrando quÃ© deberÃ­a pasar.

**Bueno:**

```python
def test_retry_3_veces_operaciones_fallidas():
    intentos = 0
    def operacion():
        nonlocal intentos
        intentos += 1
        if intentos < 3:
            raise Exception('fallo')
        return 'Ã©xito'
    
    resultado = retry_operation(operacion)
    
    assert resultado == 'Ã©xito'
    assert intentos == 3
```

Nombre claro, testea comportamiento real, una cosa

**Malo:**

```python
def test_retry_funciona():
    mock = Mock(side_effect=[Exception(), Exception(), 'Ã©xito'])
    retry_operation(mock)
    assert [mock.call](http://mock.call)_count == 3
```

Nombre vago, testea el mock no el cÃ³digo

### Verificar RED - Ver que Falle

**OBLIGATORIO. Nunca saltear.**

```bash
pytest tests/ruta/[test.py](http://test.py) -v
```

Confirmar:

- Test falla (no errores)
- Mensaje de falla es el esperado
- Falla porque la feature no existe (no typos)

**Â¿El test pasa?** EstÃ¡s testeando comportamiento existente. Arregla el test.

### GREEN - CÃ³digo MÃ­nimo

Escribir el cÃ³digo mÃ¡s simple para pasar el test.

**Bueno:** Solo lo suficiente para pasar

**Malo:** Over-engineered con features extras

No agregar features, refactorear otro cÃ³digo, o "mejorar" mÃ¡s allÃ¡ del test.

### Verificar GREEN - Ver que Pase

**OBLIGATORIO.**

Confirmar:

- Test pasa
- Otros tests siguen pasando
- Output limpio (sin errores, warnings)

### REFACTOR - Limpiar

Solo despuÃ©s de verde:

- Remover duplicaciÃ³n
- Mejorar nombres
- Extraer helpers

Mantener tests verdes. No agregar comportamiento.

### Racionalizaciones Comunes

| Excusa | Realidad |
| --- | --- |
| "Muy simple para testear" | El cÃ³digo simple se rompe. El test toma 30 segundos. |
| "Voy a testear despuÃ©s" | Tests que pasan inmediatamente no prueban nada. |
| "Ya lo testeÃ© manualmente" | Ad-hoc â‰  sistemÃ¡tico. Sin registro, no se puede re-correr. |
| "Borrar X horas es desperdicio" | Falacia de costo hundido. Mantener cÃ³digo sin verificar es deuda tÃ©cnica. |
| "Necesito explorar primero" | OK. Bota la exploraciÃ³n, empieza con TDD. |
| "TDD me va a hacer mÃ¡s lento" | TDD es mÃ¡s rÃ¡pido que debuggear. |

---

## verification-before-completion

> **Usar cuando estÃ¡s a punto de decir que el trabajo estÃ¡ completo, arreglado, o pasando, ANTES de commitear o crear PRs.**
> 

### LA LEY DE HIERRO

```
NINGÃšN CLAIM DE COMPLETADO SIN EVIDENCIA FRESCA DE VERIFICACIÃ“N
```

Si no corriste el comando de verificaciÃ³n en este mensaje, no puedes clamar que pasa.

### La FunciÃ³n de Gate

```
ANTES de clamar cualquier status o expresar satisfacciÃ³n:

1. IDENTIFICAR: Â¿QuÃ© comando prueba este claim?
2. CORRER: Ejecutar el comando COMPLETO (fresco, completo)
3. LEER: Output completo, verificar exit code, contar fallas
4. VERIFICAR: Â¿El output confirma el claim?
   - Si NO: Declarar status actual con evidencia
   - Si SÃ: Declarar claim CON evidencia
5. SOLO ENTONCES: Hacer el claim

Saltear cualquier paso = mentir, no verificar
```

### Fallas Comunes

| Claim | Requiere | NO Suficiente |
| --- | --- | --- |
| Tests pasan | Output del comando: 0 fallas | Corrida anterior, "deberÃ­a pasar" |
| Linter limpio | Output del linter: 0 errores | Chequeo parcial |
| Build exitoso | Comando de build: exit 0 | Linter pasando |
| Bug arreglado | Testear sÃ­ntoma original: pasa | CÃ³digo cambiado, asumir arreglado |
| Agente completÃ³ | VCS diff muestra cambios | Agente reporta "Ã©xito" |

### Red Flags - PARA

- Usar "deberÃ­a", "probablemente", "parece que"
- Expresar satisfacciÃ³n antes de verificaciÃ³n ("Â¡Genial!", "Â¡Perfecto!", "Â¡Listo!")
- A punto de commitear/push/PR sin verificaciÃ³n
- Confiar en reportes de Ã©xito de agentes
- Depender de verificaciÃ³n parcial
- Pensar "solo esta vez"
- Cansado y querer que el trabajo termine

### PrevenciÃ³n de RacionalizaciÃ³n

| Excusa | Realidad |
| --- | --- |
| "DeberÃ­a funcionar ahora" | CORRE la verificaciÃ³n |
| "Estoy confiado" | Confianza â‰  evidencia |
| "Solo esta vez" | Sin excepciones |
| "El linter pasÃ³" | Linter â‰  compilador |
| "El agente dijo Ã©xito" | Verifica independientemente |
| "Estoy cansado" | Cansancio â‰  excusa |

---

## code-reviewer

> **Usar cuando un paso mayor del proyecto se completÃ³ y necesita revisiÃ³n contra el plan original y estÃ¡ndares de cÃ³digo.**
> 

### QuÃ© Hace el Code Reviewer

1. **AnÃ¡lisis de AlineaciÃ³n con Plan:**
    - Comparar implementaciÃ³n contra documento de planning original
    - Identificar desviaciones del enfoque planeado
    - Evaluar si las desviaciones son mejoras justificadas o departures problemÃ¡ticos
    - Verificar que toda la funcionalidad planeada fue implementada
2. **EvaluaciÃ³n de Calidad de CÃ³digo:**
    - Revisar adherencia a patrones y convenciones establecidas
    - Chequear manejo de errores apropiado, type safety, programaciÃ³n defensiva
    - Evaluar organizaciÃ³n del cÃ³digo, convenciones de nombres, mantenibilidad
    - Evaluar cobertura de tests y calidad de implementaciÃ³n de tests
    - Buscar vulnerabilidades de seguridad o issues de performance
3. **IdentificaciÃ³n de Issues:**
    - Categorizar issues como: CrÃ­tico (debe arreglar), Importante (deberÃ­a arreglar), o Sugerencias
    - Para cada issue, proveer ejemplos especÃ­ficos y recomendaciones accionables

---

## receiving-code-review

> **Usar cuando recibes feedback de code review, ANTES de implementar sugerencias.**
> 

### El PatrÃ³n de Respuesta

```
CUANDO recibes feedback de code review:

1. LEER: Feedback completo sin reaccionar
2. ENTENDER: Reformular el requirement en tus palabras (o preguntar)
3. VERIFICAR: Chequear contra realidad del codebase
4. EVALUAR: Â¿TÃ©cnicamente correcto para ESTE codebase?
5. RESPONDER: Acknowledgment tÃ©cnico o pushback razonado
6. IMPLEMENTAR: Un item a la vez, testear cada uno
```

### Respuestas Prohibidas

**NUNCA:**

- "Â¡Tienes toda la razÃ³n!"
- "Â¡Buen punto!"
- "Â¡Excelente feedback!"
- "DÃ©jame implementar eso ahora" (antes de verificaciÃ³n)

**EN CAMBIO:**

- Reformular el requirement tÃ©cnico
- Hacer preguntas clarificadoras
- Push back con razonamiento tÃ©cnico si estÃ¡ mal
- Solo empezar a trabajar (acciones > palabras)

### CuÃ¡ndo Hacer Push Back

Hacer push back cuando:

- La sugerencia rompe funcionalidad existente
- El reviewer no tiene contexto completo
- Viola YAGNI (feature no usada)
- TÃ©cnicamente incorrecto para este stack
- Hay razones de legacy/compatibilidad

**CÃ³mo hacer push back:**

- Usar razonamiento tÃ©cnico, no defensividad
- Hacer preguntas especÃ­ficas
- Referenciar tests/cÃ³digo funcionando

---

# 5. SKILLS DE GIT

## using-git-worktrees

> **Usar cuando empiezas trabajo de feature que necesita aislamiento del workspace actual.**
> 

### Proceso de SelecciÃ³n de Directorio

**Orden de prioridad:**

1. Chequear directorios existentes:

```bash
ls -d .worktrees 2>/dev/null     # Preferido (oculto)
ls -d worktrees 2>/dev/null      # Alternativa
```

1. Chequear [CLAUDE.md](http://CLAUDE.md)
2. Preguntar al usuario

### Pasos de CreaciÃ³n

```bash
# Detectar nombre de proyecto
project=$(basename "$(git rev-parse --show-toplevel)")

# Crear worktree con nueva rama
git worktree add "$path" -b "$BRANCH_NAME"
cd "$path"

# Correr setup del proyecto
if [ -f package.json ]; then npm install; fi
if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

# Verificar baseline limpio
npm test  # o pytest, etc.
```

---

## finishing-a-development-branch

> **Usar cuando la implementaciÃ³n estÃ¡ completa, todos los tests pasan, y necesitas decidir cÃ³mo integrar el trabajo.**
> 

### El Proceso

**Paso 1: Verificar Tests**

```bash
npm test / pytest / go test ./...
```

**Si los tests fallan:** Para. No proceder al Paso 2.

**Paso 2: Presentar Opciones**

```
ImplementaciÃ³n completa. Â¿QuÃ© te gustarÃ­a hacer?

1. Merge back a <base-branch> localmente
2. Push y crear Pull Request
3. Mantener la rama como estÃ¡ (yo lo manejo despuÃ©s)
4. Descartar este trabajo

Â¿CuÃ¡l opciÃ³n?
```

**Paso 3: Ejecutar OpciÃ³n Elegida**

| OpciÃ³n | Merge | Push | Mantener Worktree | Cleanup Branch |
| --- | --- | --- | --- | --- |
| 1. Merge local | âœ“ | - | - | âœ“ |
| 2. Crear PR | - | âœ“ | âœ“ | - |
| 3. Mantener | - | - | âœ“ | - |
| 4. Descartar | - | - | - | âœ“ (force) |

---

# 6. APLICACIÃ“N A TU BOT DE TRADING v2

## Tu Problema con v1

1. Construiste el bot
2. Ganaste 7k
3. Asumiste que funcionaba sin verificar
4. Lo quemaste y perdiste todo
5. SeÃ±ales diferentes en dispositivos

**Skills que habrÃ­an prevenido esto:**

- `test-driven-development` â†’ Tests antes de cÃ³digo
- `verification-before-completion` â†’ No decir "funciona" sin pruebas
- `brainstorming` â†’ Pensar en edge cases antes

## El Flujo Correcto para v2

### Fase 1: DiseÃ±o (usa brainstorming)

1. Definir exactamente quÃ© hace el bot
2. Proponer 2-3 arquitecturas
3. Validar cada secciÃ³n del diseÃ±o
4. Documentar en `docs/plans/[YYYY-MM-DD-trading-bot-design.md](http://YYYY-MM-DD-trading-bot-design.md)`

### Fase 2: Plan (usa writing-plans)

1. Dividir en tareas de 2-5 minutos cada una
2. Cada tarea: test â†’ verificar falla â†’ implementar â†’ verificar pasa â†’ commit
3. Guardar en `docs/plans/[YYYY-MM-DD-trading-bot-implementation.md](http://YYYY-MM-DD-trading-bot-implementation.md)`

### Fase 3: ImplementaciÃ³n (usa executing-plans + TDD)

1. Ejecutar batches de 3 tareas
2. Reportar despuÃ©s de cada batch
3. NUNCA decir "funciona" sin correr tests
4. NUNCA commitear sin verificaciÃ³n

### Fase 4: VerificaciÃ³n (usa verification-before-completion)

Antes de decir "el bot estÃ¡ listo":

```bash
# Correr tests
pytest tests/ -v

# Ver output completo
# Contar fallas: 0
# SOLO ENTONCES: "El bot pasa todos los tests"
```

### Fase 5: Paper Trading (30 dÃ­as MÃNIMO)

No ir a real hasta:

- 30 dÃ­as de paper trading
- Win rate > 50%
- Drawdown definido
- Todas las verificaciones pasan

---

# Checklist Final

## Antes de CUALQUIER cÃ³digo:

- [ ]  Â¿UsÃ© brainstorming para diseÃ±ar?
- [ ]  Â¿Tengo un plan escrito con pasos de 2-5 min?
- [ ]  Â¿Cada paso tiene su test?

## Durante implementaciÃ³n:

- [ ]  Â¿EscribÃ­ el test ANTES del cÃ³digo?
- [ ]  Â¿Vi el test fallar?
- [ ]  Â¿EscribÃ­ el cÃ³digo MÃNIMO para pasar?
- [ ]  Â¿Vi el test pasar?
- [ ]  Â¿CommiteÃ©?

## Antes de decir "funciona":

- [ ]  Â¿CorrÃ­ el comando de verificaciÃ³n?
- [ ]  Â¿Vi el output completo?
- [ ]  Â¿Hay 0 fallas?
- [ ]  Â¿TENGO EVIDENCIA?

## Antes de ir a real:

- [ ]  Â¿30 dÃ­as de paper trading?
- [ ]  Â¿Win rate documentado?
- [ ]  Â¿LÃ­mite de pÃ©rdida diaria configurado?
- [ ]  Â¿Una sola fuente de datos?
- [ ]  Â¿Una sola timezone?

---

*Esta documentaciÃ³n estÃ¡ basada en el repositorio Superpowers de Jesse Vincent ([github.com/obra/superpowers](http://github.com/obra/superpowers)) - el framework usado por desarrolladores profesionales para construir software con agentes de IA sin cagar el palo.*

[ğŸš« Testing Anti-Patterns - QuÃ© NO Hacer](https://www.notion.so/Testing-Anti-Patterns-Qu-NO-Hacer-2ecf95ac6b6981d69564e24f14565b35?pvs=21)

[ğŸ§  Principios de PersuasiÃ³n para DiseÃ±o de Skills](https://www.notion.so/Principios-de-Persuasi-n-para-Dise-o-de-Skills-2ecf95ac6b6981d58d75fd6335db372a?pvs=21)

[ğŸ“ˆ Skill: TJR Price Action - Estrategia Completa](https://www.notion.so/Skill-TJR-Price-Action-Estrategia-Completa-2ecf95ac6b6981d78c52cd6c2374f0db?pvs=21)

[ğŸš€ Trading Bot v2 - Roadmap Completo](https://www.notion.so/Trading-Bot-v2-Roadmap-Completo-2ecf95ac6b698191adc8c3ca97c65ebd?pvs=21)

[ğŸ› ï¸ CÃ³mo Crear Tus Propias Skills](https://www.notion.so/C-mo-Crear-Tus-Propias-Skills-2ecf95ac6b6981f78b55e545602fa9f6?pvs=21)

[ğŸ¯ Quick Reference - Cheat Sheet](https://www.notion.so/Quick-Reference-Cheat-Sheet-2ecf95ac6b69817e9d40ff0105d0438a?pvs=21)

[ğŸ“˜ Anthropic Best Practices - GuÃ­a Oficial](https://www.notion.so/Anthropic-Best-Practices-Gu-a-Oficial-2ecf95ac6b698178858bcf15a331925f?pvs=21)
